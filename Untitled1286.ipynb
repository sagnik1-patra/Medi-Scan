{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a970bf3a-f787-4487-aa5f-876635402c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Scanning images under: C:\\Users\\sagni\\Downloads\\MediScan\\archive\\data\n",
      "[INFO] Manifest built with 129 rows.\n",
      "[INFO] Columns: ['filename', 'relpath', 'abspath', 'ext', 'size_bytes', 'sha256_head', 'width', 'height', 'mode', 'format', 'dpi_x', 'dpi_y']\n",
      "[INFO] Head:\n",
      "   filename  relpath                                            abspath   ext  \\\n",
      "0    1.jpg    1.jpg  C:\\Users\\sagni\\Downloads\\MediScan\\archive\\data...  .jpg   \n",
      "1   10.jpg   10.jpg  C:\\Users\\sagni\\Downloads\\MediScan\\archive\\data...  .jpg   \n",
      "2  100.jpg  100.jpg  C:\\Users\\sagni\\Downloads\\MediScan\\archive\\data...  .jpg   \n",
      "\n",
      "   size_bytes                                        sha256_head  width  \\\n",
      "0        3045  33cebf97759ee401a51888d144bdb3772d414c1f65308b...    304   \n",
      "1       52552  8e9da3ea572989d50af64c660f800d9282c88a575ad044...    960   \n",
      "2      154430  83073b39b38f80528728bcb07db78670856b6899bee2dc...   1200   \n",
      "\n",
      "   height mode format dpi_x dpi_y  \n",
      "0     351    P    GIF  None  None  \n",
      "1    1280  RGB   JPEG  None  None  \n",
      "2     921  RGB   JPEG   600   600  \n",
      "[WRITE] Pickle  -> C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_images.pkl\n",
      "[WRITE] HDF5    -> C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_images.h5\n",
      "[WRITE] JSON    -> C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_images.json\n",
      "[WRITE] YAML    -> C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_images.yaml\n",
      "\n",
      "[DONE] Files saved in: C:\\Users\\sagni\\Downloads\\MediScan\n",
      " - C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_images.pkl\n",
      " - C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_images.h5\n",
      " - C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_images.json\n",
      " - C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_images.yaml\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# MediScan â€” Image Manifest -> PKL / H5 / JSON / YAML  (Final, robust)\n",
    "# ==============================================\n",
    "\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# ----- Optional YAML -----\n",
    "try:\n",
    "    import yaml\n",
    "    HAVE_YAML = True\n",
    "except Exception:\n",
    "    HAVE_YAML = False\n",
    "    print(\"[WARN] PyYAML not installed; YAML output will be skipped.\")\n",
    "\n",
    "# ----- Paths -----\n",
    "IN_DIR  = Path(r\"C:\\Users\\sagni\\Downloads\\MediScan\\archive\\data\")\n",
    "OUT_DIR = Path(r\"C:\\Users\\sagni\\Downloads\\MediScan\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BASE = \"medi_scan_images\"\n",
    "PKL_PATH  = OUT_DIR / f\"{BASE}.pkl\"\n",
    "H5_PATH   = OUT_DIR / f\"{BASE}.h5\"\n",
    "JSON_PATH = OUT_DIR / f\"{BASE}.json\"\n",
    "YAML_PATH = OUT_DIR / f\"{BASE}.yaml\"\n",
    "\n",
    "# ----- Config -----\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\", \".bmp\", \".webp\"}\n",
    "HASH_BYTES = 1024 * 1024  # 1 MB for fast fingerprinting\n",
    "\n",
    "def fast_sha256(path: Path, n_bytes: int = HASH_BYTES) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    try:\n",
    "        with open(path, \"rb\") as f:\n",
    "            h.update(f.read(n_bytes))\n",
    "        return h.hexdigest()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def safe_image_open(path: Path) -> Dict[str, Any]:\n",
    "    try:\n",
    "        with Image.open(path) as img:\n",
    "            w, h = img.size\n",
    "            dpi_x, dpi_y = None, None\n",
    "            dpi = img.info.get(\"dpi\")\n",
    "            if isinstance(dpi, (tuple, list)) and len(dpi) >= 2:\n",
    "                dpi_x, dpi_y = dpi[0], dpi[1]\n",
    "            return {\n",
    "                \"width\": w,\n",
    "                \"height\": h,\n",
    "                \"mode\": img.mode,\n",
    "                \"format\": img.format,\n",
    "                \"dpi_x\": dpi_x,\n",
    "                \"dpi_y\": dpi_y,\n",
    "            }\n",
    "    except Exception:\n",
    "        return {\"width\": None, \"height\": None, \"mode\": None, \"format\": None, \"dpi_x\": None, \"dpi_y\": None}\n",
    "\n",
    "def list_images(root: Path) -> List[Path]:\n",
    "    if not root.exists():\n",
    "        print(f\"[ERROR] Input directory does not exist: {root}\")\n",
    "        return []\n",
    "    return [p for p in root.rglob(\"*\") if p.is_file() and p.suffix.lower() in IMG_EXTS]\n",
    "\n",
    "def build_manifest(root: Path) -> pd.DataFrame:\n",
    "    files = list_images(root)\n",
    "    if not files:\n",
    "        print(f\"[WARN] No image files found under {root}\")\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"filename\",\"relpath\",\"abspath\",\"ext\",\"size_bytes\",\"sha256_head\",\n",
    "            \"width\",\"height\",\"mode\",\"format\",\"dpi_x\",\"dpi_y\"\n",
    "        ])\n",
    "\n",
    "    rows: List[Dict[str, Any]] = []\n",
    "    for i, p in enumerate(files, start=1):\n",
    "        try:\n",
    "            stat = p.stat()\n",
    "            meta = safe_image_open(p)\n",
    "            rows.append({\n",
    "                \"filename\": p.name,\n",
    "                \"relpath\": str(p.relative_to(root)),\n",
    "                \"abspath\": str(p.resolve()),\n",
    "                \"ext\": p.suffix.lower(),\n",
    "                \"size_bytes\": int(stat.st_size),\n",
    "                \"sha256_head\": fast_sha256(p, HASH_BYTES),\n",
    "                \"width\": meta[\"width\"],\n",
    "                \"height\": meta[\"height\"],\n",
    "                \"mode\": meta[\"mode\"],\n",
    "                \"format\": meta[\"format\"],\n",
    "                \"dpi_x\": meta[\"dpi_x\"],\n",
    "                \"dpi_y\": meta[\"dpi_y\"],\n",
    "            })\n",
    "        except Exception as e:\n",
    "            rows.append({\n",
    "                \"filename\": p.name,\n",
    "                \"relpath\": str(p.relative_to(root)),\n",
    "                \"abspath\": str(p.resolve()),\n",
    "                \"ext\": p.suffix.lower(),\n",
    "                \"size_bytes\": None,\n",
    "                \"sha256_head\": \"\",\n",
    "                \"width\": None, \"height\": None, \"mode\": None, \"format\": None,\n",
    "                \"dpi_x\": None, \"dpi_y\": None,\n",
    "                \"error\": str(e),\n",
    "            })\n",
    "        if i % 200 == 0:\n",
    "            print(f\"[INFO] Processed {i} images...\")\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values([\"relpath\", \"filename\"]).reset_index(drop=True)\n",
    "    print(f\"[INFO] Manifest built with {len(df)} rows.\")\n",
    "    return df\n",
    "\n",
    "# ---------- Type coercion helpers ----------\n",
    "NUMERIC_COLS = [\"size_bytes\", \"width\", \"height\", \"dpi_x\", \"dpi_y\"]\n",
    "\n",
    "def coerce_for_hdf(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Convert to HDF5-friendly dtypes (no Pandas extension dtypes).\"\"\"\n",
    "    g = df.copy()\n",
    "\n",
    "    # 1) numeric columns -> float64 (NaNs allowed)\n",
    "    for c in NUMERIC_COLS:\n",
    "        if c in g.columns:\n",
    "            g[c] = pd.to_numeric(g[c], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "    # 2) non-numeric/object columns -> plain Python strings (object dtype)\n",
    "    for c in g.columns:\n",
    "        if c not in NUMERIC_COLS:\n",
    "            # Keep None for missing; convert non-missing to str\n",
    "            g[c] = g[c].where(g[c].isna(), g[c].astype(str))\n",
    "\n",
    "    return g\n",
    "\n",
    "def coerce_for_json(df: pd.DataFrame) -> list[dict]:\n",
    "    \"\"\"Return a list of JSON-serializable dicts (NaN/NA -> None; no extension dtypes).\"\"\"\n",
    "    g = df.copy()\n",
    "\n",
    "    # numeric as floats\n",
    "    for c in NUMERIC_COLS:\n",
    "        if c in g.columns:\n",
    "            g[c] = pd.to_numeric(g[c], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "    # Replace all pandas/np missing with None\n",
    "    g = g.where(pd.notna(g), None)\n",
    "\n",
    "    # Ensure everything else is basic Python types\n",
    "    records = []\n",
    "    for rec in g.to_dict(orient=\"records\"):\n",
    "        clean = {}\n",
    "        for k, v in rec.items():\n",
    "            if isinstance(v, (np.floating, np.integer)):\n",
    "                v = float(v) if isinstance(v, np.floating) else int(v)\n",
    "            elif isinstance(v, (np.bool_,)):\n",
    "                v = bool(v)\n",
    "            elif v is None:\n",
    "                v = None\n",
    "            else:\n",
    "                v = str(v) if not isinstance(v, (str, int, float, bool, type(None))) else v\n",
    "            clean[k] = v\n",
    "        records.append(clean)\n",
    "    return records\n",
    "\n",
    "def save_all(df: pd.DataFrame):\n",
    "    # ---- PKL ----\n",
    "    print(f\"[WRITE] Pickle  -> {PKL_PATH}\")\n",
    "    df.to_pickle(PKL_PATH)\n",
    "\n",
    "    # ---- HDF5 ----\n",
    "    try:\n",
    "        print(f\"[WRITE] HDF5    -> {H5_PATH}\")\n",
    "        df_h5 = coerce_for_hdf(df)\n",
    "        df_h5.to_hdf(H5_PATH, key=\"images\", mode=\"w\", format=\"table\")\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not write HDF5: {e}\\n       Hint: pip install tables (64-bit Python)\")\n",
    "\n",
    "    # ---- JSON ----\n",
    "    print(f\"[WRITE] JSON    -> {JSON_PATH}\")\n",
    "    records = coerce_for_json(df)\n",
    "    with open(JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    # ---- YAML ----\n",
    "    if HAVE_YAML:\n",
    "        try:\n",
    "            print(f\"[WRITE] YAML    -> {YAML_PATH}\")\n",
    "            with open(YAML_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "                yaml.safe_dump(records, f, allow_unicode=True, sort_keys=False)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Could not write YAML: {e}\")\n",
    "    else:\n",
    "        print(\"[INFO] Skipping YAML (PyYAML not installed).\")\n",
    "\n",
    "# ----- Run -----\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"[INFO] Scanning images under: {IN_DIR}\")\n",
    "    manifest_df = build_manifest(IN_DIR)\n",
    "    print(\"[INFO] Columns:\", list(manifest_df.columns))\n",
    "    print(\"[INFO] Head:\\n\", manifest_df.head(3))\n",
    "    save_all(manifest_df)\n",
    "\n",
    "    print(\"\\n[DONE] Files saved in:\", OUT_DIR)\n",
    "    print(\" -\", PKL_PATH)\n",
    "    print(\" -\", H5_PATH)\n",
    "    print(\" -\", JSON_PATH)\n",
    "    if HAVE_YAML:\n",
    "        print(\" -\", YAML_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818deb27-c87d-4b40-89c5-a1cea81c59c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
