{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "607f59ad-d6bb-4cbb-922a-159c21eb7c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Features CSV -> C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_features.csv\n",
      "[SAVED] Feature correlation heatmap -> C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_feature_corr_heatmap.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVED] Confusion heatmap -> C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_confusion_heatmap.png\n",
      "[SAVED] Predictions CSV -> C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_predictions.csv\n",
      "[SAVED] Model -> C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_model.pkl\n",
      "\n",
      "Done.\n",
      "Outputs:\n",
      " - C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_features.csv\n",
      " - C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_feature_corr_heatmap.png\n",
      " - C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_confusion_heatmap.png\n",
      " - C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_predictions.csv\n",
      " - C:\\Users\\sagni\\Downloads\\MediScan\\medi_scan_model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MediScan — Pseudo-Label Prediction + Heatmaps (Full Script)\n",
    "# ============================================================\n",
    "# Inputs:\n",
    "#   - Images under C:\\Users\\sagni\\Downloads\\MediScan\\archive\\data  (recursive)\n",
    "#\n",
    "# Outputs in C:\\Users\\sagni\\Downloads\\MediScan:\n",
    "#   - medi_scan_features.csv\n",
    "#   - medi_scan_feature_corr_heatmap.png\n",
    "#   - medi_scan_confusion_heatmap.png\n",
    "#   - medi_scan_predictions.csv\n",
    "#   - medi_scan_model.pkl  (StandardScaler + LogisticRegression pipeline)\n",
    "#\n",
    "# Notes:\n",
    "#   - Uses KMeans to create pseudo-labels (no ground truth).\n",
    "#   - Trains multinomial LogisticRegression to predict those labels.\n",
    "#   - Confusion heatmap is w.r.t. pseudo-labels (not true classes).\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import canny\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# ----------------------------\n",
    "# Paths / Config\n",
    "# ----------------------------\n",
    "IN_DIR  = Path(r\"C:\\Users\\sagni\\Downloads\\MediScan\\archive\\data\")\n",
    "OUT_DIR = Path(r\"C:\\Users\\sagni\\Downloads\\MediScan\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FEATURES_CSV = OUT_DIR / \"medi_scan_features.csv\"\n",
    "PRED_CSV     = OUT_DIR / \"medi_scan_predictions.csv\"\n",
    "CORR_PNG     = OUT_DIR / \"medi_scan_feature_corr_heatmap.png\"\n",
    "CM_PNG       = OUT_DIR / \"medi_scan_confusion_heatmap.png\"\n",
    "MODEL_PKL    = OUT_DIR / \"medi_scan_model.pkl\"\n",
    "\n",
    "IMG_EXTS = {\".jpg\", \".jpeg\", \".png\", \".tif\", \".tiff\", \".bmp\", \".webp\"}\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def list_images(root: Path) -> List[Path]:\n",
    "    if not root.exists():\n",
    "        raise FileNotFoundError(f\"Input directory does not exist: {root}\")\n",
    "    return [p for p in root.rglob(\"*\") if p.is_file() and p.suffix.lower() in IMG_EXTS]\n",
    "\n",
    "def extract_features_one(path: Path, hist_bins: int = 16, edge_resize: int = 256) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Extract numeric features from an image:\n",
    "      - width/height/aspect_ratio\n",
    "      - mean/std of RGB channels\n",
    "      - grayscale brightness & contrast\n",
    "      - edge density (Canny on resized gray)\n",
    "      - grayscale histogram (hist_bins, L1-normalized)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with Image.open(path) as im:\n",
    "            im = im.convert(\"RGB\")\n",
    "            w, h = im.size\n",
    "            arr = np.asarray(im, dtype=np.float32) / 255.0\n",
    "\n",
    "        width, height = float(w), float(h)\n",
    "        aspect = float(w / h) if h else np.nan\n",
    "\n",
    "        r, g, b = arr[..., 0], arr[..., 1], arr[..., 2]\n",
    "        mean_r, mean_g, mean_b = float(r.mean()), float(g.mean()), float(b.mean())\n",
    "        std_r,  std_g,  std_b  = float(r.std()),  float(g.std()),  float(b.std())\n",
    "\n",
    "        gray = rgb2gray(arr)\n",
    "        bright = float(gray.mean())\n",
    "        contrast = float(gray.std())\n",
    "\n",
    "        # Edge density on resized gray (keep aspect)\n",
    "        if min(h, w) > 0 and min(h, w) != edge_resize:\n",
    "            scale = edge_resize / min(h, w)\n",
    "            new_w, new_h = int(w * scale), int(h * scale)\n",
    "            gray_small = np.asarray(Image.fromarray((gray*255).astype(np.uint8)).resize((new_w, new_h))) / 255.0\n",
    "        else:\n",
    "            gray_small = gray\n",
    "        edges = canny(gray_small, sigma=1.5)\n",
    "        edge_density = float(edges.mean())\n",
    "\n",
    "        # Gray histogram\n",
    "        hist, _ = np.histogram((gray * 255.0).astype(np.uint8), bins=hist_bins, range=(0, 255))\n",
    "        hist = hist.astype(np.float32)\n",
    "        hist = hist / (hist.sum() + 1e-9)\n",
    "\n",
    "        feats = {\n",
    "            \"filename\": path.name,\n",
    "            \"relpath\": str(path.relative_to(IN_DIR)),\n",
    "            \"width\": width, \"height\": height, \"aspect_ratio\": aspect,\n",
    "            \"mean_r\": mean_r, \"mean_g\": mean_g, \"mean_b\": mean_b,\n",
    "            \"std_r\": std_r, \"std_g\": std_g, \"std_b\": std_b,\n",
    "            \"brightness\": bright, \"contrast\": contrast,\n",
    "            \"edge_density\": edge_density,\n",
    "        }\n",
    "        for i, v in enumerate(hist):\n",
    "            feats[f\"hist_{i:02d}\"] = float(v)\n",
    "\n",
    "        return feats\n",
    "\n",
    "    except Exception as e:\n",
    "        # Return NaNs if we fail to parse this image\n",
    "        base = {\n",
    "            \"filename\": path.name,\n",
    "            \"relpath\": str(path.relative_to(IN_DIR)),\n",
    "            \"width\": np.nan, \"height\": np.nan, \"aspect_ratio\": np.nan,\n",
    "            \"mean_r\": np.nan, \"mean_g\": np.nan, \"mean_b\": np.nan,\n",
    "            \"std_r\": np.nan, \"std_g\": np.nan, \"std_b\": np.nan,\n",
    "            \"brightness\": np.nan, \"contrast\": np.nan,\n",
    "            \"edge_density\": np.nan,\n",
    "        }\n",
    "        for i in range(16):\n",
    "            base[f\"hist_{i:02d}\"] = np.nan\n",
    "        base[\"error\"] = str(e)\n",
    "        return base\n",
    "\n",
    "def plot_confusion_heatmap(cm: np.ndarray, labels: list, title: str, out_path: Path):\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    im = plt.imshow(cm, aspect='equal')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True (pseudo-label)\")\n",
    "    plt.colorbar(im)\n",
    "    plt.xticks(range(len(labels)), labels)\n",
    "    plt.yticks(range(len(labels)), labels)\n",
    "    # annotate counts\n",
    "    for (i, j), v in np.ndenumerate(cm):\n",
    "        plt.text(j, i, str(v), ha='center', va='center')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=220)\n",
    "    plt.close()\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Load images & extract features\n",
    "# ----------------------------\n",
    "paths = list_images(IN_DIR)\n",
    "rows = [extract_features_one(p) for p in paths]\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Drop rows missing core features\n",
    "core = [\"width\", \"height\", \"aspect_ratio\", \"brightness\", \"contrast\", \"edge_density\"]\n",
    "df_clean = df.dropna(subset=core).reset_index(drop=True)\n",
    "\n",
    "# Save feature table for reference\n",
    "df_clean.to_csv(FEATURES_CSV, index=False)\n",
    "print(\"[SAVED] Features CSV ->\", FEATURES_CSV)\n",
    "\n",
    "# Numeric feature matrix\n",
    "non_feat_cols = {\"filename\", \"relpath\", \"error\"}\n",
    "feat_cols = [c for c in df_clean.columns if c not in non_feat_cols]\n",
    "feat_cols = [c for c in feat_cols if pd.api.types.is_numeric_dtype(df_clean[c])]\n",
    "X_all = df_clean[feat_cols].astype(float).values\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Correlation heatmap (features)\n",
    "# ----------------------------\n",
    "corr = df_clean[feat_cols].corr(numeric_only=True)\n",
    "plt.figure(figsize=(10, 8))\n",
    "im = plt.imshow(corr.values, aspect='auto')\n",
    "plt.xticks(range(corr.shape[1]), corr.columns, rotation=45, ha='right')\n",
    "plt.yticks(range(corr.shape[0]), corr.index)\n",
    "plt.title(\"MediScan: Feature Correlation Heatmap\")\n",
    "plt.colorbar(im)\n",
    "plt.tight_layout()\n",
    "plt.savefig(CORR_PNG, dpi=220)\n",
    "plt.close()\n",
    "print(\"[SAVED] Feature correlation heatmap ->\", CORR_PNG)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Pseudo-labels with KMeans\n",
    "# ----------------------------\n",
    "k = 3 if len(df_clean) >= 60 else 2\n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "pseudo_labels = kmeans.fit_predict(X_all)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Train/test split & model training (multinomial Logistic)\n",
    "# ----------------------------\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X_all, pseudo_labels, np.arange(len(pseudo_labels)),\n",
    "    test_size=0.2, random_state=42, stratify=pseudo_labels\n",
    ")\n",
    "\n",
    "# Build a pipeline: Standardize -> LogisticRegression (multinomial)\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        multi_class=\"multinomial\",\n",
    "        solver=\"saga\",       # good for larger feature spaces\n",
    "        C=1.0,\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=400,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Confusion matrix heatmap on test set\n",
    "y_pred_test = pipe.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_test, labels=list(range(k)))\n",
    "plot_confusion_heatmap(\n",
    "    cm, labels=[f\"C{i}\" for i in range(k)],\n",
    "    title=\"MediScan: Confusion Matrix (pseudo-label classifier)\",\n",
    "    out_path=CM_PNG\n",
    ")\n",
    "print(\"[SAVED] Confusion heatmap ->\", CM_PNG)\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Predict for ALL images & save CSV (with top-3 probabilities)\n",
    "# ----------------------------\n",
    "# Fit scaler on all, then refit LR on all (better final model) — optional but common\n",
    "pipe_all = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        multi_class=\"multinomial\",\n",
    "        solver=\"saga\",\n",
    "        C=1.0,\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=400,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "pipe_all.fit(X_all, pseudo_labels)\n",
    "\n",
    "# Predict labels + probabilities\n",
    "pred_labels = pipe_all.predict(X_all)\n",
    "probs = pipe_all.predict_proba(X_all)  # shape (N, k)\n",
    "\n",
    "# For readability, compute top-3 (label, prob) pairs per image\n",
    "def top3(prob_row):\n",
    "    idxs = np.argsort(prob_row)[::-1][:3]\n",
    "    return [(int(i), float(prob_row[i])) for i in idxs]\n",
    "\n",
    "top3_list = [top3(p) for p in probs]\n",
    "max_prob = probs.max(axis=1)\n",
    "\n",
    "out_df = pd.DataFrame({\n",
    "    \"filename\": df_clean[\"filename\"],\n",
    "    \"relpath\": df_clean[\"relpath\"],\n",
    "    \"pred_cluster\": pred_labels,\n",
    "    \"pred_prob\": max_prob\n",
    "})\n",
    "# Add probability columns per cluster\n",
    "for i in range(k):\n",
    "    out_df[f\"prob_C{i}\"] = probs[:, i]\n",
    "\n",
    "# (Optional) dump a compact string of top3\n",
    "out_df[\"top3\"] = [str(t) for t in top3_list]\n",
    "\n",
    "out_df.to_csv(PRED_CSV, index=False)\n",
    "print(\"[SAVED] Predictions CSV ->\", PRED_CSV)\n",
    "\n",
    "# Save the final model\n",
    "joblib.dump(pipe_all, MODEL_PKL)\n",
    "print(\"[SAVED] Model ->\", MODEL_PKL)\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "print(\"Outputs:\")\n",
    "print(\" -\", FEATURES_CSV)\n",
    "print(\" -\", CORR_PNG)\n",
    "print(\" -\", CM_PNG)\n",
    "print(\" -\", PRED_CSV)\n",
    "print(\" -\", MODEL_PKL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ca2efb-2e58-4d0c-9435-5dcab740640e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
